# ğŸ˜ï¸ Scraper de ImÃ³veis - DFImÃ³veis | Lucas Rodor

Este projeto realiza a **coleta automÃ¡tica de imÃ³veis Ã  venda** no portal [DFImoveis.com.br](https://www.dfimoveis.com.br), usando **Selenium + Pandas**, trata os dados com expressÃµes regulares e salva os resultados em:

- âœ… Um arquivo Excel (com timestamp)
- âœ… Um banco de dados MySQL (**apenas novos registros**, evitando duplicatas)

Esse projeto foi uma avaliaÃ§Ã£o da disciplina Projeto em CiÃªncia de Dados II do curso CiÃªncia de Dados & InteligÃªncia Artificial | IBMEC - DF, ministrada pelo professor [Laerte Jun Takeuti](https://www.linkedin.com/in/laertejt/)

---
## ğŸ‘¤ Autor

Desenvolvido por **Lucas Rodor**:
- [LinkedIn](https://www.linkedin.com/in/lucasrodor)
- [GitHub](https://github.com/lucasrodor)
---

## ğŸ§  Principais funcionalidades

- ğŸ§­ Filtra imÃ³veis por:
  - Tipo de operaÃ§Ã£o (ex: venda)
  - Tipo de imÃ³vel (ex: apartamento)
  - LocalizaÃ§Ã£o, cidade, bairro
  - NÃºmero de quartos
  - PreÃ§o mÃ©dio
  - Palavra-chave (endereÃ§o ou empreendimento)

- ğŸ“„ Extrai:
  - TÃ­tulo, preÃ§o, endereÃ§o
  - Detalhes (tamanho, quartos, vagas, suÃ­tes, plantas)
  - DescriÃ§Ã£o do anÃºncio
  - Link do imÃ³vel

- ğŸ§¹ Trata os dados:
  - Normaliza acentuaÃ§Ã£o
  - Extrai dados estruturados dos detalhes usando Regex
  - Preenche campo `data_extracao` com timestamp

- ğŸ’¾ Salva:
  - Em planilha Excel (pasta `/data`)
  - Em banco de dados MySQL (**evitando duplicatas via link**)

---

## ğŸš€ Tecnologias utilizadas

- Python 3.10+
- Selenium
- Pandas
- SQLAlchemy
- PyMySQL
- python-dotenv
- openpyxl
- re (regex)

---

## ğŸ“¦ Estrutura do projeto

```
â”œâ”€â”€ main.py
â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ navegador.py
â”‚   â”œâ”€â”€ filtros.py
â”‚   â”œâ”€â”€ extrator.py
â”‚   â””â”€â”€ tratamento.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ banco.py
â”‚   â””â”€â”€ excel.py
â”œâ”€â”€ data/                # arquivos Excel salvos
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Como rodar localmente

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/lucasrodor/AP1_LucasRodor_webScrapping.git
cd AP1_LucasRodor_webScrapping
```

### 2. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

### 3. Crie um arquivo `.env` com suas credenciais do MySQL:
```
MYSQL_USER=seu_usuario
MYSQL_PASSWORD=sua_senha
```

### 4. Configure o banco de dados e tabela
```sql
CREATE DATABASE db_imoveis;
USE db_imoveis;

CREATE TABLE imoveis (
    id INT AUTO_INCREMENT PRIMARY KEY,
    titulo VARCHAR(255),
    preco DECIMAL(15,2),
    endereco VARCHAR(255),
    detalhes TEXT,
    descricao TEXT,
    link VARCHAR(500) UNIQUE,
    tamanho VARCHAR(20),
    quartos VARCHAR(20),
    vagas VARCHAR(20),
    suites VARCHAR(20),
    plantas VARCHAR(20),
    data_extracao DATETIME
);
```

### 5. Execute o script
```bash
python main.py
```

---

## âœ… Exemplo de uso no cÃ³digo
```python
from scraping.navegador import iniciar_navegador
from scraping.filtros import aplicar_filtros
from scraping.extrator import extrair_dados
from scraping.tratamento import tratar_dataframe
from utils.banco import salvar_mysql
from utils.excel import salvar_excel

# pipeline manual
navegador = iniciar_navegador()
aplicar_filtros(navegador, tipo_operacao="VENDA", tipo_imovel="APARTAMENTO", cidade="AGUAS CLARAS")
df = extrair_dados(navegador)
navegador.quit()

df = tratar_dataframe(df)
salvar_excel(df)
salvar_mysql(df)
```

---


---

## ğŸ“Œ ObservaÃ§Ãµes
- O script usa o navegador Chrome. Certifique-se de ter o **Google Chrome** e o **ChromeDriver** compatÃ­vel instalados.
- Para rodar em modo invisÃ­vel (sem abrir o navegador), ative a opÃ§Ã£o `headless=True` ao chamar `iniciar_navegador()`.

